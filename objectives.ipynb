{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6202f581-7491-4f5d-b6ed-075d75a93dd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyspark in ./.local/lib/python3.10/site-packages (3.3.2)\n",
      "Requirement already satisfied: py4j==0.10.9.5 in ./.local/lib/python3.10/site-packages (from pyspark) (0.10.9.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5bd998d-01db-44ac-81a7-45b82569b930",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09726a12-9ebf-48d1-92e8-74c0c2746ceb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/28 12:17:04 WARN Utils: Your hostname, TIGER03179 resolves to a loopback address: 127.0.1.1; using 172.29.167.7 instead (on interface eth0)\n",
      "23/04/28 12:17:04 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/28 12:17:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark=SparkSession.builder.appName(\"Sample\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19c04748-b2ab-490e-829f-3b51d1dd61b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "350effb4-bdce-4275-a9a3-7e93fa776653",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a92c5a74-b958-4ef5-9780-1b3ec633397f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a848d87-85f3-4b49-940d-4539d45e3dbc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.29.167.7:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Sample</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fd6f84106d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd71e29a-e334-4a92-b0da-a16e677e5f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:17\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M\")\n",
    "print(current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1eb11ae1-d639-4fbb-bb9a-1a7fb08cb8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_df = spark.read.csv(\"dataset/customers.csv\", inferSchema = True, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d99fed1-0957-47bd-ba41-3328d2b50bfd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#cust_df.repartition(\"location\").write.partitionBy(\"location\").parquet(\"dataset/location/\")\n",
    "\n",
    "cust_df.write.partitionBy(\"location\").parquet('dataset/location_'+current_time+'/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f749c1a4-83dc-4f78-be6c-9fc715277f3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pip install mysql-connector-python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a13b412-8e00-4fd2-9057-cdc04f32c7ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff8ec840-5968-40e6-a77e-7e407d6a6d4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30ace4f2-0b50-4179-be69-11d6dadfb31f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af2f39a8-d9de-4766-89e9-51effc6af749",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0.33\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "print(mysql.connector.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3aed438-4402-4495-9d92-633942ced57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read single parquet into df\n",
    "\n",
    "import pandas as pd\n",
    "#pq_df = pd.read_parquet('dataset/location/location=London/part-00000-269157be-fc13-4c02-acb4-f71127cf6179.c000.snappy.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f37f66f3-0240-4b82-bf02-5cd6743f092f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(pq_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37b4ebbf-d2d6-4fea-adbc-51a652be24b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sqlalchemy import create_engine\\nimport pymysql\\nimport pandas as pd\\nengine = create_engine(\"mysql+pymysql://{user}:{pw}@localhost/{db}\"\\n                       .format(user=\"swapnil\",\\n                               pw=\"swapnil123\",\\n                               db=\"mysql\"))\\n#dbConnection    = engine.connect()\\npq_df.to_sql(\\'pq_pune\\', engine, if_exists = \\'append\\', chunksize = 1000)'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sqlalchemy import create_engine\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "engine = create_engine(\"mysql+pymysql://{user}:{pw}@localhost/{db}\"\n",
    "                       .format(user=\"swapnil\",\n",
    "                               pw=\"swapnil123\",\n",
    "                               db=\"mysql\"))\n",
    "#dbConnection    = engine.connect()\n",
    "pq_df.to_sql('pq_pune', engine, if_exists = 'append', chunksize = 1000)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c3570b3-2eea-4691-ba77-169232b60722",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype   \n",
      "---  ------         --------------  -----   \n",
      " 0   customer_id    500 non-null    int32   \n",
      " 1   customer_name  500 non-null    object  \n",
      " 2   location       500 non-null    category\n",
      "dtypes: category(1), int32(1), object(1)\n",
      "memory usage: 7.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Objective - 2\n",
    "# Parquet Dataset --> df \n",
    "\n",
    "import pyarrow.parquet as pq\n",
    "parquet_df = pq.ParquetDataset('dataset/location_'+current_time+'/').read_pandas().to_pandas()\n",
    "parquet_df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31efa27b-e21f-4c7b-9110-a265aa626f5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df --> MySQL table : No need to create schema in MySQL\n",
    "'''from sqlalchemy import create_engine\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "\n",
    "engine = create_engine(\"mysql+pymysql://{user}:{pw}@localhost/{db}\"\n",
    "                       .format(user=\"swapnil\",\n",
    "                               pw=\"swapnil123\",\n",
    "                               db=\"mysql\"))\n",
    "#dbConnection    = engine.connect()\n",
    "parquet_df.to_sql('parquet_table',engine, if_exists = 'append', chunksize = 1000)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7cbfadb-0c00-42b2-a3c2-7c5d8a5233d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Objective - 3\n",
    "########### Casting - Masking ###########################\n",
    "# using repartition\n",
    "\n",
    "mask_df = spark.read.csv(\"dataset/cast_mask.csv\", inferSchema = True, header = True)\n",
    "mask_df.repartition(1).write.partitionBy(\"location\").parquet('dataset/cast_mask_'+current_time+'/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba515131-5ff5-447e-b77f-da5c53facf9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "parquet_df1 = spark.read.parquet('dataset/cast_mask_'+current_time+'/')\n",
    "\n",
    "# This is assuming your card number is not a string. If not skip this cast\n",
    "parquet_cast = parquet_df1.withColumn(\"credit_card\",F.col('credit_card').cast(StringType()))\n",
    "parquet_mask = parquet_cast.withColumn(\"masked_credit_card\",F.concat(F.lit('******'),F.substring(F.col(\"credit_card\"),7,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46d43e88-6146-4df3-a7d7-682ca7c397f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-----------+--------+------------------+\n",
      "|customer_id|customer_name|credit_card|location|masked_credit_card|\n",
      "+-----------+-------------+-----------+--------+------------------+\n",
      "|        160|   Rock Melon| 1231231234|    Rome|        ******1234|\n",
      "|        275|   Rose Greek| 9999999999|    Rome|        ******9999|\n",
      "|        100|   Rose Mario| 3333333333|    Rome|        ******3333|\n",
      "|         85|     Sam Ever| 9999999999|    Rome|        ******9999|\n",
      "|         10|  Super Mario| 9876543210|    Rome|        ******3210|\n",
      "|        435|  Adina Melon| 9102837465|    Rome|        ******7465|\n",
      "|        350| Carina Smith| 1029384756|    Rome|        ******4756|\n",
      "|        125|  Brook Melon| 1029388475|    Rome|        ******8475|\n",
      "|        360|   Rose Melon| 9087654321|    Rome|        ******4321|\n",
      "|        475|    Brook lee| 9102837465|    Rome|        ******7465|\n",
      "|        410|   Chris Gyle| 5182058395|    Rome|        ******8395|\n",
      "|        335|    Sam Mario| 1029388475|    Rome|        ******8475|\n",
      "|        485|   John Mario| 9879876547|    Rome|        ******6547|\n",
      "|        250|     Sam Gyle| 9879876547|    Rome|        ******6547|\n",
      "|        135| Carina Smith| 9102837465|    Rome|        ******7465|\n",
      "|         35|     Sam Gyle| 6666666666|    Rome|        ******6666|\n",
      "|        460|   Rock Gyle | 5182058395|    Rome|        ******8395|\n",
      "|        235|  Devid Mario| 9876543210|    Rome|        ******3210|\n",
      "|        200|    John Gyle| 1231231234|    Rome|        ******1234|\n",
      "|        425|   Brook Ever| 9102837465|    Rome|        ******7465|\n",
      "+-----------+-------------+-----------+--------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parquet_mask.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0af41ec-efa1-4873-86e0-77988950b1de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Storing df in a single parquet file\n",
    "parquet_mask.repartition(1).write.parquet(\"dataset/cast_mask_parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7cb2bf33-5238-4093-a7c3-d35c077d1365",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-----------+--------+------------------+\n",
      "|customer_id|customer_name|credit_card|location|masked_credit_card|\n",
      "+-----------+-------------+-----------+--------+------------------+\n",
      "|        160|   Rock Melon| 1231231234|    Rome|        ******1234|\n",
      "|        275|   Rose Greek| 9999999999|    Rome|        ******9999|\n",
      "|        100|   Rose Mario| 3333333333|    Rome|        ******3333|\n",
      "|         85|     Sam Ever| 9999999999|    Rome|        ******9999|\n",
      "|         10|  Super Mario| 9876543210|    Rome|        ******3210|\n",
      "|        435|  Adina Melon| 9102837465|    Rome|        ******7465|\n",
      "|        350| Carina Smith| 1029384756|    Rome|        ******4756|\n",
      "|        125|  Brook Melon| 1029388475|    Rome|        ******8475|\n",
      "|        360|   Rose Melon| 9087654321|    Rome|        ******4321|\n",
      "|        475|    Brook lee| 9102837465|    Rome|        ******7465|\n",
      "|        410|   Chris Gyle| 5182058395|    Rome|        ******8395|\n",
      "|        335|    Sam Mario| 1029388475|    Rome|        ******8475|\n",
      "|        485|   John Mario| 9879876547|    Rome|        ******6547|\n",
      "|        250|     Sam Gyle| 9879876547|    Rome|        ******6547|\n",
      "|        135| Carina Smith| 9102837465|    Rome|        ******7465|\n",
      "|         35|     Sam Gyle| 6666666666|    Rome|        ******6666|\n",
      "|        460|   Rock Gyle | 5182058395|    Rome|        ******8395|\n",
      "|        235|  Devid Mario| 9876543210|    Rome|        ******3210|\n",
      "|        200|    John Gyle| 1231231234|    Rome|        ******1234|\n",
      "|        425|   Brook Ever| 9102837465|    Rome|        ******7465|\n",
      "+-----------+-------------+-----------+--------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parquet_mask.show(20)\n",
    "#spark.sql('''select * from parquet_mask limit 10''').createOrReplaceTempView(\"mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f477b90f-feae-4798-8538-d099d0def924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective - 5: customers data: csv --> df --> parquet --> df \n",
    "customers_df = spark.read.csv(\"dataset/customers.csv\", inferSchema = True, header = True)\n",
    "customers_df.repartition(1).write.partitionBy(\"location\").parquet('dataset/customers_parquet_'+current_time+'/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e54b2dc-b872-4157-8c67-bdb9a067f957",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "customers_df = spark.read.parquet('dataset/customers_parquet_'+current_time+'/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ca0a93c-afd9-42e0-84b8-4419e80d4518",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+--------+\n",
      "|customer_id|customer_name|location|\n",
      "+-----------+-------------+--------+\n",
      "|          2|   Jack Melon|  Berlin|\n",
      "|         14|   Rose Mario|  Berlin|\n",
      "|         27|    Jack Gyle|  Berlin|\n",
      "|         39|  Brook Melon|  Berlin|\n",
      "|         52|   David Ever|  Berlin|\n",
      "|         64|  Devid Smith|  Berlin|\n",
      "|         77|    Sam Mario|  Berlin|\n",
      "|         89|    Adina lee|  Berlin|\n",
      "|        102|   Rose Melon|  Berlin|\n",
      "|        114|    John Gyle|  Berlin|\n",
      "|        127|  Brook Smith|  Berlin|\n",
      "|        139|   David Gyle|  Berlin|\n",
      "|        152|   Chris Gyle|  Berlin|\n",
      "|        164|     Sam Gyle|  Berlin|\n",
      "|        177|  Adina Melon|  Berlin|\n",
      "|        189|   Rose Greek|  Berlin|\n",
      "|        202|   Rock Gyle |  Berlin|\n",
      "|        214|     Sam Ever|  Berlin|\n",
      "|        227|   John Mario|  Berlin|\n",
      "|        239|  Chris Melon|  Berlin|\n",
      "+-----------+-------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customers_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3b843cc-3bd9-4c4a-8da6-ec1dc8079c82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+--------+\n",
      "|customer_id|customer_name|location|\n",
      "+-----------+-------------+--------+\n",
      "|          2|   Jac*******|  Berlin|\n",
      "|         14|   Ros*******|  Berlin|\n",
      "|         27|    Jac******|  Berlin|\n",
      "|         39|  Bro********|  Berlin|\n",
      "|         52|   Dav*******|  Berlin|\n",
      "|         64|  Dev********|  Berlin|\n",
      "|         77|    Sam******|  Berlin|\n",
      "|         89|    Adi******|  Berlin|\n",
      "|        102|   Ros*******|  Berlin|\n",
      "|        114|    Joh******|  Berlin|\n",
      "|        127|  Bro********|  Berlin|\n",
      "|        139|   Dav*******|  Berlin|\n",
      "|        152|   Chr*******|  Berlin|\n",
      "|        164|     Sam*****|  Berlin|\n",
      "|        177|  Adi********|  Berlin|\n",
      "|        189|   Ros*******|  Berlin|\n",
      "|        202|   Roc*******|  Berlin|\n",
      "|        214|     Sam*****|  Berlin|\n",
      "|        227|   Joh*******|  Berlin|\n",
      "|        239|  Chr********|  Berlin|\n",
      "+-----------+-------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customers_df.createOrReplaceTempView(\"customers\")\n",
    "spark.sql(\"\"\"SELECT customer_id,CONCAT(SUBSTR(customer_name, 1, 3), REPEAT('*', CHAR_LENGTH(customer_name) - 3)) AS customer_name,location\n",
    "FROM customers\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fb50c0c8-762d-4b87-aa7a-149a8e6e6c90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+--------+\n",
      "|customer_id|customer_name|location|\n",
      "+-----------+-------------+--------+\n",
      "|          2|   *******lon|  Berlin|\n",
      "|         14|   *******rio|  Berlin|\n",
      "|         27|    ******yle|  Berlin|\n",
      "|         39|  ********lon|  Berlin|\n",
      "|         52|   *******ver|  Berlin|\n",
      "|         64|  ********ith|  Berlin|\n",
      "|         77|    ******rio|  Berlin|\n",
      "|         89|    ******lee|  Berlin|\n",
      "|        102|   *******lon|  Berlin|\n",
      "|        114|    ******yle|  Berlin|\n",
      "|        127|  ********ith|  Berlin|\n",
      "|        139|   *******yle|  Berlin|\n",
      "|        152|   *******yle|  Berlin|\n",
      "|        164|     *****yle|  Berlin|\n",
      "|        177|  ********lon|  Berlin|\n",
      "|        189|   *******eek|  Berlin|\n",
      "|        202|   *******le |  Berlin|\n",
      "|        214|     *****ver|  Berlin|\n",
      "|        227|   *******rio|  Berlin|\n",
      "|        239|  ********lon|  Berlin|\n",
      "+-----------+-------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT customer_id,CONCAT(REPEAT('*', CHAR_LENGTH(customer_name) - 3), SUBSTR(customer_name, CHAR_LENGTH(customer_name) - 2, 4)) AS customer_name,location\n",
    "FROM customers\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e858de52-24f2-4dca-accc-8f5f383bb384",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encrypted:\n",
      "\n",
      "+-----------+-------------+--------+\n",
      "|customer_id|customer_name|location|\n",
      "+-----------+-------------+--------+\n",
      "|          2|   noleM kcaJ|  Berlin|\n",
      "|         14|   oiraM esoR|  Berlin|\n",
      "|         27|    elyG kcaJ|  Berlin|\n",
      "|         39|  noleM koorB|  Berlin|\n",
      "|         52|   revE divaD|  Berlin|\n",
      "|         64|  htimS diveD|  Berlin|\n",
      "|         77|    oiraM maS|  Berlin|\n",
      "|         89|    eel anidA|  Berlin|\n",
      "|        102|   noleM esoR|  Berlin|\n",
      "|        114|    elyG nhoJ|  Berlin|\n",
      "|        127|  htimS koorB|  Berlin|\n",
      "|        139|   elyG divaD|  Berlin|\n",
      "|        152|   elyG sirhC|  Berlin|\n",
      "|        164|     elyG maS|  Berlin|\n",
      "|        177|  noleM anidA|  Berlin|\n",
      "|        189|   keerG esoR|  Berlin|\n",
      "|        202|    elyG kcoR|  Berlin|\n",
      "|        214|     revE maS|  Berlin|\n",
      "|        227|   oiraM nhoJ|  Berlin|\n",
      "|        239|  noleM sirhC|  Berlin|\n",
      "+-----------+-------------+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "\n",
      "Decrypted:\n",
      "\n",
      "+-----------+-------------+--------+\n",
      "|customer_id|customer_name|location|\n",
      "+-----------+-------------+--------+\n",
      "|          2|   Jack Melon|  Berlin|\n",
      "|         14|   Rose Mario|  Berlin|\n",
      "|         27|    Jack Gyle|  Berlin|\n",
      "|         39|  Brook Melon|  Berlin|\n",
      "|         52|   David Ever|  Berlin|\n",
      "|         64|  Devid Smith|  Berlin|\n",
      "|         77|    Sam Mario|  Berlin|\n",
      "|         89|    Adina lee|  Berlin|\n",
      "|        102|   Rose Melon|  Berlin|\n",
      "|        114|    John Gyle|  Berlin|\n",
      "|        127|  Brook Smith|  Berlin|\n",
      "|        139|   David Gyle|  Berlin|\n",
      "|        152|   Chris Gyle|  Berlin|\n",
      "|        164|     Sam Gyle|  Berlin|\n",
      "|        177|  Adina Melon|  Berlin|\n",
      "|        189|   Rose Greek|  Berlin|\n",
      "|        202|   Rock Gyle |  Berlin|\n",
      "|        214|     Sam Ever|  Berlin|\n",
      "|        227|   John Mario|  Berlin|\n",
      "|        239|  Chris Melon|  Berlin|\n",
      "+-----------+-------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Objective 3 - Casting and Masking\n",
    "from pyspark.sql.functions import reverse \n",
    "customers_df1 = customers_df.select(customers_df['customer_id'],reverse(customers_df['customer_name']),customers_df['location'])\n",
    "customers_df1 = customers_df1.select(customers_df1['customer_id'], customers_df1['reverse(customer_name)'].alias('customer_name'), customers_df1['location'])\n",
    "print(\"\\nEncrypted:\\n\")\n",
    "customers_df1.show()\n",
    "customers_df2 = customers_df1.select(customers_df1['customer_id'],reverse(customers_df1['customer_name']),customers_df1['location'])\n",
    "customers_df2 = customers_df2.select(customers_df2['customer_id'], customers_df2['reverse(customer_name)'].alias('customer_name'), customers_df2['location'])\n",
    "print(\"\\nDecrypted:\\n\")\n",
    "customers_df2.show()\n",
    "#customers_df1.select(customers_df1['customer_id'], customers_df1['reverse(customer_name)'].alias('customer_name'), customers_df1['location']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72ce7afc-314e-4612-9faf-5e1ebd167375",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encrypted:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------+\n",
      "|customer_id|      encrypted_name|location|\n",
      "+-----------+--------------------+--------+\n",
      "|          2|gAAAAABkS2v9EsVei...|  Berlin|\n",
      "|         14|gAAAAABkS2v9e3wcc...|  Berlin|\n",
      "|         27|gAAAAABkS2v9Vrhm-...|  Berlin|\n",
      "|         39|gAAAAABkS2v9DcC-z...|  Berlin|\n",
      "|         52|gAAAAABkS2v9k00mP...|  Berlin|\n",
      "|         64|gAAAAABkS2v9saiYR...|  Berlin|\n",
      "|         77|gAAAAABkS2v9Li5Eg...|  Berlin|\n",
      "|         89|gAAAAABkS2v9lLCyu...|  Berlin|\n",
      "|        102|gAAAAABkS2v9V-l0x...|  Berlin|\n",
      "|        114|gAAAAABkS2v9ngkGG...|  Berlin|\n",
      "|        127|gAAAAABkS2v9qzFIr...|  Berlin|\n",
      "|        139|gAAAAABkS2v9rVHUX...|  Berlin|\n",
      "|        152|gAAAAABkS2v9XGP8v...|  Berlin|\n",
      "|        164|gAAAAABkS2v9pKDZS...|  Berlin|\n",
      "|        177|gAAAAABkS2v9EjIvo...|  Berlin|\n",
      "|        189|gAAAAABkS2v9-uW-r...|  Berlin|\n",
      "|        202|gAAAAABkS2v9Rpd8W...|  Berlin|\n",
      "|        214|gAAAAABkS2v90mkdW...|  Berlin|\n",
      "|        227|gAAAAABkS2v9fsOgM...|  Berlin|\n",
      "|        239|gAAAAABkS2v9QHXLT...|  Berlin|\n",
      "+-----------+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "\n",
      "Decrypted:\n",
      "\n",
      "+-----------+--------------+--------+\n",
      "|customer_id|decrypted_name|location|\n",
      "+-----------+--------------+--------+\n",
      "|          2|    Jack Melon|  Berlin|\n",
      "|         14|    Rose Mario|  Berlin|\n",
      "|         27|     Jack Gyle|  Berlin|\n",
      "|         39|   Brook Melon|  Berlin|\n",
      "|         52|    David Ever|  Berlin|\n",
      "|         64|   Devid Smith|  Berlin|\n",
      "|         77|     Sam Mario|  Berlin|\n",
      "|         89|     Adina lee|  Berlin|\n",
      "|        102|    Rose Melon|  Berlin|\n",
      "|        114|     John Gyle|  Berlin|\n",
      "|        127|   Brook Smith|  Berlin|\n",
      "|        139|    David Gyle|  Berlin|\n",
      "|        152|    Chris Gyle|  Berlin|\n",
      "|        164|      Sam Gyle|  Berlin|\n",
      "|        177|   Adina Melon|  Berlin|\n",
      "|        189|    Rose Greek|  Berlin|\n",
      "|        202|    Rock Gyle |  Berlin|\n",
      "|        214|      Sam Ever|  Berlin|\n",
      "|        227|    John Mario|  Berlin|\n",
      "|        239|   Chris Melon|  Berlin|\n",
      "+-----------+--------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import udf, lit, col\n",
    "from cryptography.fernet import Fernet\n",
    "\n",
    "# encrypt func\n",
    "def encrypt_data(plain_text, KEY):\n",
    "    f = Fernet(KEY)\n",
    "    encrip_text = f.encrypt(str(plain_text).encode()).decode()\n",
    "    return encrip_text\n",
    "encrypt_udf = udf(encrypt_data, StringType())\n",
    "\n",
    "# generate the encryption key\n",
    "Key = Fernet.generate_key()\n",
    "\n",
    "enc_df = customers_df.withColumn(\"encrypted_name\", encrypt_udf(col('customer_name'), lit(Key))) \n",
    "print(\"\\nEncrypted:\\n\")\n",
    "enc_df.select(['customer_id','encrypted_name','location']).show()\n",
    "\n",
    "\n",
    "def decrypt_data(encrypt_data, KEY):\n",
    "    f = Fernet(bytes(KEY))\n",
    "    decoded_val = f.decrypt(encrypt_data.encode()).decode()\n",
    "    return decoded_val\n",
    "decrypt_udf = udf(decrypt_data, StringType())\n",
    "# decrypt the data\n",
    "dec_df = enc_df.withColumn(\"decrypted_name\", decrypt_udf(col('encrypted_name'), lit(Key)))\n",
    "print(\"\\nDecrypted:\\n\")\n",
    "dec_df.select(['customer_id','decrypted_name','location']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "df49d5ad-7f56-4724-ba9f-096b20e29d11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Data: \n",
      "\n",
      "+-----------+-------------+--------+\n",
      "|customer_id|customer_name|location|\n",
      "+-----------+-------------+--------+\n",
      "|          2|   Jack Melon|  Berlin|\n",
      "|         14|   Rose Mario|  Berlin|\n",
      "|         27|    Jack Gyle|  Berlin|\n",
      "|         39|  Brook Melon|  Berlin|\n",
      "|         52|   David Ever|  Berlin|\n",
      "|         64|  Devid Smith|  Berlin|\n",
      "|         77|    Sam Mario|  Berlin|\n",
      "|         89|    Adina lee|  Berlin|\n",
      "|        102|   Rose Melon|  Berlin|\n",
      "|        114|    John Gyle|  Berlin|\n",
      "+-----------+-------------+--------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Masked Data: \n",
      "\n",
      "+-----------+--------+-------------+\n",
      "|customer_id|location|customer_name|\n",
      "+-----------+--------+-------------+\n",
      "|          2|  Berlin|   Jacxxxxlon|\n",
      "|         14|  Berlin|   Rosxxxxrio|\n",
      "|         27|  Berlin|    Jacxxxxle|\n",
      "|         39|  Berlin|  Broxxxxelon|\n",
      "|         52|  Berlin|   Davxxxxver|\n",
      "|         64|  Berlin|  Devxxxxmith|\n",
      "|         77|  Berlin|    Samxxxxio|\n",
      "|         89|  Berlin|    Adixxxxee|\n",
      "|        102|  Berlin|   Rosxxxxlon|\n",
      "|        114|  Berlin|    Johxxxxle|\n",
      "+-----------+--------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "def main():\n",
    "    customers_df = spark.read.parquet('dataset/customers_parquet_'+current_time+'/')\n",
    "    print (\"Input Data: \\n\")\n",
    "    customers_df.show(10)\n",
    "    mask_func_udf = udf(mask_func, StringType())\n",
    "    df_masked=customers_df.withColumn(\"name_masked\",mask_func_udf(customers_df[\"customer_name\"]))\n",
    "    df_masked=df_masked.drop(\"customer_name\").withColumnRenamed(\"name_masked\",\"customer_name\")\n",
    "    print (\"Masked Data: \\n\")\n",
    "    df_masked.show(10)\n",
    "    return 0\n",
    "def mask_func(colVal):\n",
    "        charList=list(colVal)\n",
    "        charList[3:7]='x'*4\n",
    "        return \"\".join(charList)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "80db1a76-8e5f-4e9f-8ab1-774aa02f42b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "products_df = spark.read.csv(\"dataset/products.csv\", inferSchema = True, header = True)\n",
    "products_df.write.parquet('dataset/products_parquet_'+current_time+'/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f9b83c62-34e1-400c-a2c0-085961ac7d18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "products_df = spark.read.parquet('dataset/products_parquet_'+current_time+'/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dc1ed853-460c-47b7-8540-8fb68bceb661",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+-----------+\n",
      "|product_id|product_name|   category|\n",
      "+----------+------------+-----------+\n",
      "|         1|           A|Electronics|\n",
      "|         2|           B|         IT|\n",
      "|         3|           C|      Books|\n",
      "|         4|           D|       Food|\n",
      "|         5|           E|  Jewellery|\n",
      "|         6|           F|   Footwear|\n",
      "|         7|           G|     Beauty|\n",
      "|         8|           H|      Cloth|\n",
      "|         9|           I|       Wood|\n",
      "|        10|           J|      Fruit|\n",
      "|        11|           K|    Watches|\n",
      "|        12|           L|      Audio|\n",
      "|        13|           M|       Toys|\n",
      "|        14|           N|      Sport|\n",
      "|        15|           O|    Medical|\n",
      "|        16|           P|      Paper|\n",
      "|        17|           Q|  Household|\n",
      "|        18|           R|        Pet|\n",
      "|        19|           S|    Grocery|\n",
      "|        20|           T|     Drinks|\n",
      "+----------+------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "products_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8aef28b0-284d-4793-9355-0d9b4a6f9ef0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sales_df = spark.read.csv(\"dataset/sales.csv\", inferSchema = True, header = True)\n",
    "sales_df.write.parquet('dataset/sales_parquet_'+current_time+'/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bc6c301a-31e4-4e99-91cf-441da0e1e522",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sales_df = spark.read.parquet('dataset/sales_parquet_'+current_time+'/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f34b9a71-3488-4f15-8178-f3399da9787e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+-----------+-------------------+--------+-----+\n",
      "|transaction_id|product_id|customer_id|   transaction_date|quantity|price|\n",
      "+--------------+----------+-----------+-------------------+--------+-----+\n",
      "|             1|         1|          1|2021-01-02 00:00:00|      10|   20|\n",
      "|             2|         2|          2|2021-01-03 00:00:00|       9|   22|\n",
      "|             3|         3|          3|2021-01-04 00:00:00|       8|   24|\n",
      "|             4|         4|          4|2021-01-05 00:00:00|       7|   26|\n",
      "|             5|         5|          5|2021-01-06 00:00:00|       6|   28|\n",
      "|             6|         6|          6|2021-01-07 00:00:00|       5|   30|\n",
      "|             7|         7|          7|2021-01-08 00:00:00|       4|   32|\n",
      "|             8|         8|          8|2021-01-09 00:00:00|       3|   34|\n",
      "|             9|         9|          9|2021-01-10 00:00:00|       2|   36|\n",
      "|            10|        10|         10|2021-01-11 00:00:00|       1|   38|\n",
      "|            11|        11|         11|2021-01-12 00:00:00|       1|   40|\n",
      "|            12|        12|         12|2021-01-13 00:00:00|       2|   42|\n",
      "|            13|        13|         13|2021-01-14 00:00:00|       3|   44|\n",
      "|            14|        14|         14|2021-01-15 00:00:00|       4|   46|\n",
      "|            15|        15|         15|2021-01-16 00:00:00|       5|   48|\n",
      "|            16|        16|         16|2021-01-17 00:00:00|       6|   50|\n",
      "|            17|        17|         17|2021-01-18 00:00:00|       7|   52|\n",
      "|            18|        18|         18|2021-01-19 00:00:00|       8|   54|\n",
      "|            19|        19|         19|2021-01-20 00:00:00|       9|   56|\n",
      "|            20|        20|         20|2021-01-21 00:00:00|      10|   58|\n",
      "+--------------+----------+-----------+-------------------+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d2d792d7-4be6-431d-b7ed-87ab42f30ed0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>customer_name</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>John Smith</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jack Melon</td>\n",
       "      <td>Berlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>John Melon</td>\n",
       "      <td>Tokyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Jack Smith</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Mia Greek</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Jack Greek</td>\n",
       "      <td>Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>John Greek</td>\n",
       "      <td>London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Mia Smith</td>\n",
       "      <td>Mexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Mia Melon</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Super Mario</td>\n",
       "      <td>Rome</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id customer_name   location\n",
       "0            1    John Smith   New York\n",
       "1            2    Jack Melon     Berlin\n",
       "2            3    John Melon      Tokyo\n",
       "3            4    Jack Smith       Pune\n",
       "4            5     Mia Greek  Singapore\n",
       "5            6    Jack Greek      Paris\n",
       "6            7    John Greek     London\n",
       "7            8     Mia Smith     Mexico\n",
       "8            9     Mia Melon     Sydney\n",
       "9           10   Super Mario       Rome"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Objective - 4: Pre-validations/ Post-validations\n",
    "customers_df = pd.read_csv(\"dataset/customers.csv\")\n",
    "customers_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b794161e-f9dd-4ba4-8800-e2b00324793a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "city = ['New York','Berlin','Tokyo','Pune','Singapore','Paris','London','Mexico','Sydney','Rome','Mumbai','Dubai','Beijing','Chicago','Mysore','Madrid','Chennai','Hyd','Delhi','Egypt','Madras','Bombay','France']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a5b476e8-e088-4ccd-a9dd-4fbb4e660f36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>customer_name</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>John Smith</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jack Melon</td>\n",
       "      <td>Berlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>John Melon</td>\n",
       "      <td>Tokyo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Jack Smith</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Mia Greek</td>\n",
       "      <td>Singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>496</td>\n",
       "      <td>Chris Gyle</td>\n",
       "      <td>Egypt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>497</td>\n",
       "      <td>Chris Melon</td>\n",
       "      <td>Madras</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>498</td>\n",
       "      <td>Chris Mario</td>\n",
       "      <td>Bombay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>499</td>\n",
       "      <td>Rose Gyle</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>500</td>\n",
       "      <td>Swapnil M</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     customer_id customer_name   location\n",
       "0              1    John Smith   New York\n",
       "1              2    Jack Melon     Berlin\n",
       "2              3    John Melon      Tokyo\n",
       "3              4    Jack Smith       Pune\n",
       "4              5     Mia Greek  Singapore\n",
       "..           ...           ...        ...\n",
       "495          496    Chris Gyle      Egypt\n",
       "496          497   Chris Melon     Madras\n",
       "497          498   Chris Mario     Bombay\n",
       "498          499     Rose Gyle     France\n",
       "499          500     Swapnil M       Pune\n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandera as pa\n",
    "from pandera import Column, Check\n",
    "#Check.greater_than(0), \n",
    "\n",
    "# ordered=True - To validate the order of the columns\n",
    "# report_duplicates = \"all\" - report all duplicates\n",
    "# unique=[\"customer_id\"] - uniqueness of columns\n",
    "\n",
    "schema = pa.DataFrameSchema(\n",
    "    {\n",
    "        \"customer_id\": Column(int, Check.less_than(501), Check.in_range(0, 501), Check(lambda x: x.sum() > 500)),\n",
    "        \"customer_name\": Column(str, nullable=False),\n",
    "        \"location\": Column(str, Check.isin(city), nullable=False),\n",
    "    }, ordered=True, report_duplicates = \"all\", unique=[\"customer_id\"]\n",
    ")\n",
    "\n",
    "schema.validate(customers_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f3f777bc-ebc7-4e30-9d2f-21c2fa7b68d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed check: <Check less_than: less_than(480)>\n",
      "\n",
      " dataframe:\n",
      "      customer_id customer_name   location\n",
      "0              1    John Smith   New York\n",
      "1              2    Jack Melon     Berlin\n",
      "2              3    John Melon      Tokyo\n",
      "3              4    Jack Smith       Pune\n",
      "4              5     Mia Greek  Singapore\n",
      "..           ...           ...        ...\n",
      "495          496    Chris Gyle      Egypt\n",
      "496          497   Chris Melon     Madras\n",
      "497          498   Chris Mario     Bombay\n",
      "498          499     Rose Gyle     France\n",
      "499          500     Swapnil M       Pune\n",
      "\n",
      "[500 rows x 3 columns]\n",
      "\n",
      "Failure cases:\n",
      "     index  failure_case\n",
      "0     479           480\n",
      "1     480           481\n",
      "2     481           482\n",
      "3     482           483\n",
      "4     483           484\n",
      "5     484           485\n",
      "6     485           486\n",
      "7     486           487\n",
      "8     487           488\n",
      "9     488           489\n",
      "10    489           490\n",
      "11    490           491\n",
      "12    491           492\n",
      "13    492           493\n",
      "14    493           494\n",
      "15    494           495\n",
      "16    495           496\n",
      "17    496           497\n",
      "18    497           498\n",
      "19    498           499\n",
      "20    499           500\n"
     ]
    }
   ],
   "source": [
    "from pandera import check_input\n",
    "from pandera.errors import SchemaError\n",
    "\n",
    "schema = pa.DataFrameSchema(\n",
    "    {\n",
    "        \"customer_id\": Column(int, Check.less_than(480), Check.in_range(0, 501), Check(lambda x: x.sum() > 500)),\n",
    "        \"customer_name\": Column(str, nullable=False),\n",
    "        \"location\": Column(str, Check.isin(city), nullable=False),\n",
    "    }\n",
    ")\n",
    "\n",
    "try:\n",
    "  schema(customers_df)\n",
    "except SchemaError as e:\n",
    "  print(\"Failed check:\", e.check)\n",
    "  print(\"\\n dataframe:\\n\", e.data)\n",
    "  print(\"\\nFailure cases:\\n\", e.failure_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c16f8f98-a7e9-46c8-8ca1-4164c8ffcd61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125250"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply schema in function\n",
    "schema = pa.DataFrameSchema(\n",
    "    {\n",
    "        \"customer_id\": Column(int, Check.less_than(501), Check.in_range(0, 501), Check(lambda x: x.sum() > 500)),\n",
    "        \"customer_name\": Column(str, nullable=False),\n",
    "        \"location\": Column(str, Check.isin(city), nullable=False),\n",
    "    }\n",
    ")\n",
    "def get_sum_id(customers_df: pd.DataFrame, schema: pa.DataFrameSchema):\n",
    "    validated = schema.validate(customers_df)\n",
    "    return validated[\"customer_id\"].sum()\n",
    "\n",
    "get_sum_id(customers_df, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4bd199c2-dd56-41ec-b4c9-4ae15b95ca8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125250"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Input\n",
    "from pandera import check_input\n",
    "\n",
    "@check_input(schema)\n",
    "def get_sum_id(customers_df: pd.DataFrame, schema: pa.DataFrameSchema):\n",
    "    validated = schema.validate(customers_df)\n",
    "    return validated[\"customer_id\"].sum()\n",
    "\n",
    "get_sum_id(customers_df, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "423c5b15-f191-41e0-8445-93f14d735741",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from pathlib import Path\\n\\n# Get a YAML object\\nyaml_schema = schema.to_yaml()\\n\\n# Save to a file\\nf = Path(\"dataset/schema.yml\")\\nf.touch()\\nf.write_text(yaml_schema)'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from pathlib import Path\n",
    "\n",
    "# Get a YAML object\n",
    "yaml_schema = schema.to_yaml()\n",
    "\n",
    "# Save to a file\n",
    "f = Path(\"dataset/schema.yml\")\n",
    "f.touch()\n",
    "f.write_text(yaml_schema)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1c863455-a167-40ab-8f4a-7f298eee2077",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Objective - 5\n",
    "customers_df = spark.read.csv(\"dataset/customers.csv\", inferSchema = True, header = True)\n",
    "customers_df.write.parquet('dataset/customers_parquet1_'+current_time+'/')\n",
    "customers_df = spark.read.parquet('dataset/customers_parquet1_'+current_time+'/')\n",
    "\n",
    "products_df = spark.read.csv(\"dataset/products.csv\", inferSchema = True, header = True)\n",
    "products_df.write.parquet('dataset/products_parquet1_'+current_time+'/')\n",
    "products_df = spark.read.parquet('dataset/products_parquet1_'+current_time+'/')\n",
    "\n",
    "sales_df = spark.read.csv(\"dataset/sales.csv\", inferSchema = True, header = True)\n",
    "sales_df.write.parquet('dataset/sales_parquet1_'+current_time+'/')\n",
    "sales_df = spark.read.parquet('dataset/sales_parquet1_'+current_time+'/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3ac22f31-41cd-4257-aa55-7379ed2f5625",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "customers_df.createOrReplaceTempView(\"customers\")\n",
    "products_df.createOrReplaceTempView(\"products\")\n",
    "sales_df.createOrReplaceTempView(\"sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6f17e84a-11dc-46c1-b756-d71d52fd46fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+-----------+\n",
      "|product_id|product_name|   category|\n",
      "+----------+------------+-----------+\n",
      "|         1|           A|Electronics|\n",
      "|         2|           B|         IT|\n",
      "|         3|           C|      Books|\n",
      "|         4|           D|       Food|\n",
      "|         5|           E|  Jewellery|\n",
      "+----------+------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select * from products limit\"\"\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eae4a980-4941-43d6-898c-c7bc136f2b19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+-----------+-------------------+--------+-----+\n",
      "|transaction_id|product_id|customer_id|   transaction_date|quantity|price|\n",
      "+--------------+----------+-----------+-------------------+--------+-----+\n",
      "|             1|         1|          1|2021-01-02 00:00:00|      10|   20|\n",
      "|             2|         2|          2|2021-01-03 00:00:00|       9|   22|\n",
      "|             3|         3|          3|2021-01-04 00:00:00|       8|   24|\n",
      "|             4|         4|          4|2021-01-05 00:00:00|       7|   26|\n",
      "|             5|         5|          5|2021-01-06 00:00:00|       6|   28|\n",
      "+--------------+----------+-----------+-------------------+--------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select * from sales limit\"\"\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c2c69de8-4e2d-43eb-bdb6-6e43bf9c2650",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+-------------+\n",
      "|month|   category|sum(quantity)|\n",
      "+-----+-----------+-------------+\n",
      "|    1|    Medical|           26|\n",
      "|    1|        Pet|           13|\n",
      "|    1|       Wood|           42|\n",
      "|    1|       Food|           23|\n",
      "|    1|   Footwear|           42|\n",
      "|    1|     Drinks|           13|\n",
      "|    1|  Household|           13|\n",
      "|    1|  Jewellery|           42|\n",
      "|    1|      Fruit|           42|\n",
      "|    1|         IT|           22|\n",
      "|    1|      Books|           22|\n",
      "|    1|      Paper|           13|\n",
      "|    1|      Cloth|           42|\n",
      "|    1|     Beauty|           42|\n",
      "|    1|Electronics|           23|\n",
      "|    1|      Sport|           25|\n",
      "|    1|      Audio|           23|\n",
      "|    1|       Toys|           24|\n",
      "|    1|    Watches|           22|\n",
      "|    1|    Grocery|           13|\n",
      "+-----+-----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the monthly sales for each product category \n",
    "spark.sql('''select month(s.transaction_date) as month, p.category, sum(s.quantity)\n",
    "from products p INNER JOIN sales s on p.product_id = s.product_id group by month,p.category order by month''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c071143e-1d36-4f61-a1e2-a6c11a756db7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+--------+----+\n",
      "|month|product_name|quantity|rank|\n",
      "+-----+------------+--------+----+\n",
      "|    1|           D|      20|   1|\n",
      "|    2|           G|      41|   1|\n",
      "|    3|           Q|      51|   1|\n",
      "|    3|           R|      51|   1|\n",
      "|    4|           V|      30|   1|\n",
      "|    4|           W|      30|   1|\n",
      "|    4|           M|      30|   1|\n",
      "|    5|           P|      31|   1|\n",
      "|    5|           Q|      31|   1|\n",
      "|    6|           U|      23|   1|\n",
      "|    7|           J|      30|   1|\n",
      "|    7|           K|      30|   1|\n",
      "|    8|           H|      20|   1|\n",
      "|    9|           R|      30|   1|\n",
      "|    9|           S|      30|   1|\n",
      "|   10|           W|      30|   1|\n",
      "|   11|           A|      30|   1|\n",
      "|   12|           E|      40|   1|\n",
      "+-----+------------+--------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate highest selling product_name for each month\n",
    "spark.sql('''select * from (select month, product_name, quantity, rank() over(partition by month order by quantity desc) as rank from (select month(s.transaction_date) as month, p.product_name, s.quantity from products p INNER JOIN sales s\n",
    "on p.product_id=s.product_id)) where rank =1''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "39eafad2-52a4-46ba-b95e-1b3c5f1e9f33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+--------+----+\n",
      "|month|   category|quantity|rank|\n",
      "+-----+-----------+--------+----+\n",
      "|    1|      Fruit|      20|   1|\n",
      "|    1|       Wood|      19|   2|\n",
      "|    2|      Books|      41|   1|\n",
      "|    2|         IT|      40|   2|\n",
      "|    3|       Toys|      51|   1|\n",
      "|    3|      Sport|      51|   2|\n",
      "|    4|     Drinks|      30|   1|\n",
      "|    4|Electronics|      30|   2|\n",
      "|    5|   Footwear|      31|   1|\n",
      "|    5|     Beauty|      31|   2|\n",
      "|    6|    Watches|      23|   1|\n",
      "|    6|      Audio|      21|   2|\n",
      "|    7|      Audio|      30|   1|\n",
      "|    7|       Toys|      30|   2|\n",
      "|    8|         IT|      20|   1|\n",
      "|    8|Electronics|      19|   2|\n",
      "|    9|      Audio|      30|   1|\n",
      "|    9|       Toys|      30|   2|\n",
      "|   10|      Books|      30|   1|\n",
      "|   10|       Food|      28|   2|\n",
      "+-----+-----------+--------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate two highest selling category for each month\n",
    "spark.sql('''select * from (select month, category, quantity, row_number()over(partition by month order by quantity desc) as rank from (select month(s.transaction_date) as month, p.category, s.quantity\n",
    "from products p INNER JOIN sales s on p.product_id=s.product_id)) where rank < 3''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "00ccac6b-d874-420b-8da4-ad524612d61a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+-----+----+\n",
      "|month|category|total|rank|\n",
      "+-----+--------+-----+----+\n",
      "|    1|   Fruit| 1560|   1|\n",
      "|    2| Watches| 2552|   1|\n",
      "|    3|    Food| 2058|   1|\n",
      "|    4|   Books| 2380|   1|\n",
      "|    5|  Drinks|  980|   1|\n",
      "|    6| Watches|  819|   1|\n",
      "|    7|    Toys| 2910|   1|\n",
      "|    8|      IT| 1980|   1|\n",
      "|    9|     Pet| 1250|   1|\n",
      "|   10|   Books| 3000|   1|\n",
      "|   11|  Beauty|  589|   1|\n",
      "|   12|   Cloth| 3290|   1|\n",
      "+-----+--------+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate highest sale for each month\n",
    "spark.sql('''select * from(select month, category, total, rank() over(partition by month order by total desc) as rank from (select month(s.transaction_date) as month, p.category, s.price*s.quantity as total \n",
    "from products p INNER JOIN sales s on p.product_id = s.product_id)) where rank = 1''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0efae40a-d127-4504-9d97-9ee1340b8f7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+-----+----+\n",
      "|year|category|total|rank|\n",
      "+----+--------+-----+----+\n",
      "|2021|   Cloth| 3290|   1|\n",
      "|2022| Watches| 2552|   1|\n",
      "+----+--------+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate highest sale for each year\n",
    "spark.sql('''select * from(select year, category, total, row_number()over(partition by year order by total desc) as rank \n",
    "from(select year(s.transaction_date) as year, p.category, s.quantity*s.price as total \n",
    "from products p INNER JOIN sales s on p.product_id=s.product_id)) where rank = 1''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "933cbbee-c338-456c-aac1-bb19013d0bac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Check Output\\nfrom pandera import check_input, check_io\\nfrom pandera.errors import SchemaError\\n\\nin_schema = pa.DataFrameSchema(\\n    {\\n        \"customer_id\": Column(int, Check.less_than(501), Check.in_range(0, 501), Check(lambda x: x.sum() > 500)),\\n        \"customer_name\": Column(str, nullable=False),\\n        \"location\": Column(str, Check.isin(city), nullable=False),\\n    }\\n)\\n\\nout_schema = pa.DataFrameSchema(\\n    {\\n        \"customer_id\": Column(int, Check.less_than(501), Check.in_range(0, 501), Check(lambda x: x.sum() > 500)),\\n        \"customer_name\": Column(str, nullable=False),\\n        \"location\": Column(str, Check.isin(city), nullable=False),\\n    }\\n)\\n\\n@check_io(customers_df=in_schema, out=out_schema)\\ndef get_sum_id(customers_df: pd.DataFrame):    \\n    return customers_df[\"customer_id\"].sum()\\n\\nget_sum_id(customers_df)'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Check Output\n",
    "from pandera import check_input, check_io\n",
    "from pandera.errors import SchemaError\n",
    "\n",
    "in_schema = pa.DataFrameSchema(\n",
    "    {\n",
    "        \"customer_id\": Column(int, Check.less_than(501), Check.in_range(0, 501), Check(lambda x: x.sum() > 500)),\n",
    "        \"customer_name\": Column(str, nullable=False),\n",
    "        \"location\": Column(str, Check.isin(city), nullable=False),\n",
    "    }\n",
    ")\n",
    "\n",
    "out_schema = pa.DataFrameSchema(\n",
    "    {\n",
    "        \"customer_id\": Column(int, Check.less_than(501), Check.in_range(0, 501), Check(lambda x: x.sum() > 500)),\n",
    "        \"customer_name\": Column(str, nullable=False),\n",
    "        \"location\": Column(str, Check.isin(city), nullable=False),\n",
    "    }\n",
    ")\n",
    "\n",
    "@check_io(customers_df=in_schema, out=out_schema)\n",
    "def get_sum_id(customers_df: pd.DataFrame):    \n",
    "    return customers_df[\"customer_id\"].sum()\n",
    "\n",
    "get_sum_id(customers_df)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c4609cbc-6eca-48bf-978e-b1e1351aed5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pa.Check(lambda s: s.isin([\"M\", \"F\"])\\n         lambda x: x[\"age\"] < 20\\n         pa.Check(lambda s: s > 0)'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''pa.Check(lambda s: s.isin([\"M\", \"F\"])\n",
    "         lambda x: x[\"age\"] < 20\n",
    "         pa.Check(lambda s: s > 0)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d7566c1b-d4b2-4783-a714-e4e390960c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df = pd.DataFrame(\\n    {\\n        \"order_value\": [841, 487, 208, 571, 554, 225, 186, 338, 996, 260],\\n        \"gender\": [\"M\", \"M\", \"M\", \"M\", \"M\", \"F\", \"M\", \"M\", \"F\", \"F\"],\\n        \"age\": [10, 18, 8, 24, 23, 5, 23, 10, 16, 19],\\n        \"batch\": [\\n            \"2938-SS\",\\n            \"2309-TT\",\\n            \"2309-SW\",\\n            \"0923-OW\",\\n            \"5615-SD\",\\n            \"2320-LI\",\\n            \"0932-SO\",\\n            \"2308-WE\",\\n            \"9832-TC\",\\n            \"1092-PW\",\\n        ],\\n        \"student\": [True, True, False, True, False, True, True, True, False, True],\\n    }\\n)'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''df = pd.DataFrame(\n",
    "    {\n",
    "        \"order_value\": [841, 487, 208, 571, 554, 225, 186, 338, 996, 260],\n",
    "        \"gender\": [\"M\", \"M\", \"M\", \"M\", \"M\", \"F\", \"M\", \"M\", \"F\", \"F\"],\n",
    "        \"age\": [10, 18, 8, 24, 23, 5, 23, 10, 16, 19],\n",
    "        \"batch\": [\n",
    "            \"2938-SS\",\n",
    "            \"2309-TT\",\n",
    "            \"2309-SW\",\n",
    "            \"0923-OW\",\n",
    "            \"5615-SD\",\n",
    "            \"2320-LI\",\n",
    "            \"0932-SO\",\n",
    "            \"2308-WE\",\n",
    "            \"9832-TC\",\n",
    "            \"1092-PW\",\n",
    "        ],\n",
    "        \"student\": [True, True, False, True, False, True, True, True, False, True],\n",
    "    }\n",
    ")'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "99db7550-0d5e-4bad-8d6b-4f29836148e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import pandera as pa\\nfrom pandera import Column, Check\\nschema = pa.DataFrameSchema(\\n    {\\n        \"order_value\": Column(\\n            \"int64\", [Check.less_than(1000), Check.greater_than(100)]\\n        ),\\n        \"gender\": Column(\"str\", [Check.isin([\"M\", \"F\"])]),\\n        \"age\": Column(\"int64\", [Check.less_than(40), Check.greater_than(0)]),\\n        \"batch\": Column(\"str\"),\\n        \"student\": Column(\"bool\"),\\n    }\\n)'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import pandera as pa\n",
    "from pandera import Column, Check\n",
    "schema = pa.DataFrameSchema(\n",
    "    {\n",
    "        \"order_value\": Column(\n",
    "            \"int64\", [Check.less_than(1000), Check.greater_than(100)]\n",
    "        ),\n",
    "        \"gender\": Column(\"str\", [Check.isin([\"M\", \"F\"])]),\n",
    "        \"age\": Column(\"int64\", [Check.less_than(40), Check.greater_than(0)]),\n",
    "        \"batch\": Column(\"str\"),\n",
    "        \"student\": Column(\"bool\"),\n",
    "    }\n",
    ")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "98c52644-da1c-44ca-a1ea-6b2e7341845e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'schema2 = pa.DataFrameSchema(\\n    {\\n        \"order_value\": Column(\\n            \"int64\",\\n            [\\n                Check.less_than(1000),\\n                Check.greater_than(100),\\n                Check(lambda x: x.sum() > 1000),\\n            ],\\n        ),\\n        \"gender\": Column(\"str\", [Check.isin([\"M\", \"F\"])]),\\n        \"age\": Column(\"int64\", [Check.less_than(40), Check.greater_than(0)]),\\n        \"batch\": Column(\"str\", [Check.str_matches(\"\\\\d{4}-\\\\w{2}\")]),\\n        \"student\": Column(\"bool\"),\\n    }\\n)'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''schema2 = pa.DataFrameSchema(\n",
    "    {\n",
    "        \"order_value\": Column(\n",
    "            \"int64\",\n",
    "            [\n",
    "                Check.less_than(1000),\n",
    "                Check.greater_than(100),\n",
    "                Check(lambda x: x.sum() > 1000),\n",
    "            ],\n",
    "        ),\n",
    "        \"gender\": Column(\"str\", [Check.isin([\"M\", \"F\"])]),\n",
    "        \"age\": Column(\"int64\", [Check.less_than(40), Check.greater_than(0)]),\n",
    "        \"batch\": Column(\"str\", [Check.str_matches(\"\\d{4}-\\w{2}\")]),\n",
    "        \"student\": Column(\"bool\"),\n",
    "    }\n",
    ")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3c297db6-2bdd-4bcf-9a18-f6063d649896",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@pa.check_input(schema)\\n@pa.check_output(schema2)\\ndef avg_age_by_studentship(df):\\n    return df.groupby(\"student\").age.mean().reset_index()'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''@pa.check_input(schema)\n",
    "@pa.check_output(schema2)\n",
    "def avg_age_by_studentship(df):\n",
    "    return df.groupby(\"student\").age.mean().reset_index()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d131a7fc-8eb6-4129-befa-02b7c4bebe30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fruits = pd.DataFrame(\\n    {\\n        \"name\": [\"apple\", \"banana\", \"apple\", \"orange\"],\\n        \"store\": [\"Aldi\", \"Walmart\", \"Walmart\", \"Aldi\"],\\n        \"price\": [2, 1, 3, 4],\\n    }\\n)\\n\\nfruits'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''fruits = pd.DataFrame(\n",
    "    {\n",
    "        \"name\": [\"apple\", \"banana\", \"apple\", \"orange\"],\n",
    "        \"store\": [\"Aldi\", \"Walmart\", \"Walmart\", \"Aldi\"],\n",
    "        \"price\": [2, 1, 3, 4],\n",
    "    }\n",
    ")\n",
    "\n",
    "fruits'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4aa08210-e877-4ced-9c17-20417f173ac2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'available_fruits = [\"apple\", \"banana\", \"orange\"]\\nnearby_stores = [\"Aldi\", \"Walmart\"]'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''available_fruits = [\"apple\", \"banana\", \"orange\"]\n",
    "nearby_stores = [\"Aldi\", \"Walmart\"]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9092afce-ad74-4474-a7dc-5b7b1c017056",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import pandera as pa\\nfrom pandera import Column, Check\\nschema = pa.DataFrameSchema(\\n    {\\n        \"name\": Column(str, Check.isin(available_fruits)),\\n        \"store\": Column(str, Check.isin(nearby_stores)),\\n        \"price\": Column(int),\\n    }\\n)\\nschema.validate(fruits)'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import pandera as pa\n",
    "from pandera import Column, Check\n",
    "schema = pa.DataFrameSchema(\n",
    "    {\n",
    "        \"name\": Column(str, Check.isin(available_fruits)),\n",
    "        \"store\": Column(str, Check.isin(nearby_stores)),\n",
    "        \"price\": Column(int),\n",
    "    }\n",
    ")\n",
    "schema.validate(fruits)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "53ee667f-6794-454e-bffd-b800bd1131bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSchemaError: <Schema Column(name=price, type=DataType(int64))> failed element-wise validator 0:\\n<Check less_than: less_than(4)>\\nfailure cases:\\n   index  failure_case\\n0      3             4\\n'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''schema = pa.DataFrameSchema(\n",
    "    {\n",
    "        \"name\": Column(str, Check.isin(available_fruits)),\n",
    "        \"store\": Column(str, Check.isin(nearby_stores)),\n",
    "        \"price\": Column(int, Check.less_than(4)),\n",
    "    }\n",
    ")\n",
    "schema.validate(fruits)'''\n",
    "'''\n",
    "SchemaError: <Schema Column(name=price, type=DataType(int64))> failed element-wise validator 0:\n",
    "<Check less_than: less_than(4)>\n",
    "failure cases:\n",
    "   index  failure_case\n",
    "0      3             4\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6ad948c1-2c67-4a98-a8dc-4b02541369b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#Custom Checks - using lambda\\nschema = pa.DataFrameSchema(\\n    {\\n        \"name\": Column(str, Check.isin(available_fruits)),\\n        \"store\": Column(str, Check.isin(nearby_stores)),\\n        \"price\": Column(\\n            int, [Check.less_than(5), Check(lambda price: sum(price) < 20)]\\n        ),\\n    }\\n)\\nschema.validate(fruits)'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#Custom Checks - using lambda\n",
    "schema = pa.DataFrameSchema(\n",
    "    {\n",
    "        \"name\": Column(str, Check.isin(available_fruits)),\n",
    "        \"store\": Column(str, Check.isin(nearby_stores)),\n",
    "        \"price\": Column(\n",
    "            int, [Check.less_than(5), Check(lambda price: sum(price) < 20)]\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "schema.validate(fruits)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ab45f125-35fb-4ef5-b915-c51c8e067da5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Schema Model\\nfrom pandera.typing import Series\\n\\nclass Schema(pa.SchemaModel):\\n    name: Series[str] = pa.Field(isin=available_fruits)\\n    store: Series[str] = pa.Field(isin=nearby_stores)\\n    price: Series[int] = pa.Field(le=5)\\n\\n    @pa.check(\"price\")\\n    def price_sum_lt_20(cls, price: Series[int]) -> Series[bool]:\\n        return sum(price) < 20\\n\\nSchema.validate(fruits)'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Schema Model\n",
    "from pandera.typing import Series\n",
    "\n",
    "class Schema(pa.SchemaModel):\n",
    "    name: Series[str] = pa.Field(isin=available_fruits)\n",
    "    store: Series[str] = pa.Field(isin=nearby_stores)\n",
    "    price: Series[int] = pa.Field(le=5)\n",
    "\n",
    "    @pa.check(\"price\")\n",
    "    def price_sum_lt_20(cls, price: Series[int]) -> Series[bool]:\n",
    "        return sum(price) < 20\n",
    "\n",
    "Schema.validate(fruits)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "eb377b50-bf6b-4434-8d90-1be30f27cf36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fruits = pd.DataFrame(\\n    {\\n        \"name\": [\"apple\", \"banana\", \"apple\", \"orange\"],\\n        \"store\": [\"Aldi\", \"Walmart\", \"Walmart\", \"Aldi\"],\\n        \"price\": [2, 1, 3, 4],\\n    }\\n)\\n\\nschema = pa.DataFrameSchema(\\n    {\\n        \"name\": Column(str, Check.isin(available_fruits)),\\n        \"store\": Column(str, Check.isin(nearby_stores)),\\n        \"price\": Column(int, Check.less_than(5)),\\n    }\\n)\\n\\n\\ndef get_total_price(fruits: pd.DataFrame, schema: pa.DataFrameSchema):\\n    validated = schema.validate(fruits)\\n    return validated[\"price\"].sum()\\n\\n\\nget_total_price(fruits, schema)'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''fruits = pd.DataFrame(\n",
    "    {\n",
    "        \"name\": [\"apple\", \"banana\", \"apple\", \"orange\"],\n",
    "        \"store\": [\"Aldi\", \"Walmart\", \"Walmart\", \"Aldi\"],\n",
    "        \"price\": [2, 1, 3, 4],\n",
    "    }\n",
    ")\n",
    "\n",
    "schema = pa.DataFrameSchema(\n",
    "    {\n",
    "        \"name\": Column(str, Check.isin(available_fruits)),\n",
    "        \"store\": Column(str, Check.isin(nearby_stores)),\n",
    "        \"price\": Column(int, Check.less_than(5)),\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "def get_total_price(fruits: pd.DataFrame, schema: pa.DataFrameSchema):\n",
    "    validated = schema.validate(fruits)\n",
    "    return validated[\"price\"].sum()\n",
    "\n",
    "\n",
    "get_total_price(fruits, schema)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2bb460eb-ca7d-4248-90f1-82f110d08dd4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Check Input\\nfrom pandera import check_input\\n\\n@check_input(schema)\\ndef get_total_price(fruits: pd.DataFrame):\\n    return fruits.price.sum()\\n\\nget_total_price(fruits)'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Check Input\n",
    "from pandera import check_input\n",
    "\n",
    "@check_input(schema)\n",
    "def get_total_price(fruits: pd.DataFrame):\n",
    "    return fruits.price.sum()\n",
    "\n",
    "get_total_price(fruits)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "91c30729-20f5-47d1-a4e9-e570b3ab2f27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Check Output\\nfrom pandera import check_output\\n\\nfruits_nearby = pd.DataFrame(\\n    {\\n        \"name\": [\"apple\", \"banana\", \"apple\", \"orange\"],\\n        \"store\": [\"Aldi\", \"Walmart\", \"Walmart\", \"Aldi\"],\\n        \"price\": [2, 1, 3, 4],\\n    }\\n)\\n\\nfruits_faraway = pd.DataFrame(\\n    {\\n        \"name\": [\"apple\", \"banana\", \"apple\", \"orange\"],\\n        \"store\": [\"Whole Foods\", \"Whole Foods\", \"Schnucks\", \"Schnucks\"],\\n        \"price\": [3, 2, 4, 5],\\n    }\\n)\\n\\nout_schema = pa.DataFrameSchema(\\n    {\"store\": Column(str, Check.isin([\"Aldi\", \"Walmart\", \"Whole Foods\", \"Schnucks\"]))}\\n)\\n\\n\\n@check_output(out_schema)\\ndef combine_fruits(fruits_nearby: pd.DataFrame, fruits_faraway: pd.DataFrame):\\n    fruits = pd.concat([fruits_nearby, fruits_faraway])\\n    return fruits\\n\\n\\ncombine_fruits(fruits_nearby, fruits_faraway)'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Check Output\n",
    "from pandera import check_output\n",
    "\n",
    "fruits_nearby = pd.DataFrame(\n",
    "    {\n",
    "        \"name\": [\"apple\", \"banana\", \"apple\", \"orange\"],\n",
    "        \"store\": [\"Aldi\", \"Walmart\", \"Walmart\", \"Aldi\"],\n",
    "        \"price\": [2, 1, 3, 4],\n",
    "    }\n",
    ")\n",
    "\n",
    "fruits_faraway = pd.DataFrame(\n",
    "    {\n",
    "        \"name\": [\"apple\", \"banana\", \"apple\", \"orange\"],\n",
    "        \"store\": [\"Whole Foods\", \"Whole Foods\", \"Schnucks\", \"Schnucks\"],\n",
    "        \"price\": [3, 2, 4, 5],\n",
    "    }\n",
    ")\n",
    "\n",
    "out_schema = pa.DataFrameSchema(\n",
    "    {\"store\": Column(str, Check.isin([\"Aldi\", \"Walmart\", \"Whole Foods\", \"Schnucks\"]))}\n",
    ")\n",
    "\n",
    "\n",
    "@check_output(out_schema)\n",
    "def combine_fruits(fruits_nearby: pd.DataFrame, fruits_faraway: pd.DataFrame):\n",
    "    fruits = pd.concat([fruits_nearby, fruits_faraway])\n",
    "    return fruits\n",
    "\n",
    "\n",
    "combine_fruits(fruits_nearby, fruits_faraway)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6b230e2b-a91e-4fc7-8249-72de5b3ed850",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Check Both Inputs and Outputs - check_io\\nfrom pandera import check_io\\n\\nin_schema = pa.DataFrameSchema({\"store\": Column(str)})\\n\\nout_schema = pa.DataFrameSchema(\\n    {\"store\": Column(str, Check.isin([\"Aldi\", \"Walmart\", \"Whole Foods\", \"Schnucks\"]))}\\n)\\n\\n\\n@check_io(fruits_nearby=in_schema, fruits_faraway=in_schema, out=out_schema)\\ndef combine_fruits(fruits_nearby: pd.DataFrame, fruits_faraway: pd.DataFrame):\\n    fruits = pd.concat([fruits_nearby, fruits_faraway])\\n    return fruits\\n\\n\\ncombine_fruits(fruits_nearby, fruits_faraway)'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Check Both Inputs and Outputs - check_io\n",
    "from pandera import check_io\n",
    "\n",
    "in_schema = pa.DataFrameSchema({\"store\": Column(str)})\n",
    "\n",
    "out_schema = pa.DataFrameSchema(\n",
    "    {\"store\": Column(str, Check.isin([\"Aldi\", \"Walmart\", \"Whole Foods\", \"Schnucks\"]))}\n",
    ")\n",
    "\n",
    "\n",
    "@check_io(fruits_nearby=in_schema, fruits_faraway=in_schema, out=out_schema)\n",
    "def combine_fruits(fruits_nearby: pd.DataFrame, fruits_faraway: pd.DataFrame):\n",
    "    fruits = pd.concat([fruits_nearby, fruits_faraway])\n",
    "    return fruits\n",
    "\n",
    "\n",
    "combine_fruits(fruits_nearby, fruits_faraway)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ef0fb2f9-8e2c-4eb2-aa82-cb7049d0e239",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Deal with Null Values - If null values are acceptable, add nullable=True\\nimport numpy as np\\n\\nfruits = fruits = pd.DataFrame(\\n    {\\n        \"name\": [\"apple\", \"banana\", \"apple\", \"orange\"],\\n        \"store\": [\"Aldi\", \"Walmart\", \"Walmart\", np.nan],\\n        \"price\": [2, 1, 3, 4],\\n    }\\n)\\n\\nschema = pa.DataFrameSchema(\\n    {\\n        \"name\": Column(str, Check.isin(available_fruits)),\\n        \"store\": Column(str, Check.isin(nearby_stores), nullable=True),\\n        \"price\": Column(int, Check.less_than(5)),\\n    }\\n)\\nschema.validate(fruits)'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Deal with Null Values - If null values are acceptable, add nullable=True\n",
    "import numpy as np\n",
    "\n",
    "fruits = fruits = pd.DataFrame(\n",
    "    {\n",
    "        \"name\": [\"apple\", \"banana\", \"apple\", \"orange\"],\n",
    "        \"store\": [\"Aldi\", \"Walmart\", \"Walmart\", np.nan],\n",
    "        \"price\": [2, 1, 3, 4],\n",
    "    }\n",
    ")\n",
    "\n",
    "schema = pa.DataFrameSchema(\n",
    "    {\n",
    "        \"name\": Column(str, Check.isin(available_fruits)),\n",
    "        \"store\": Column(str, Check.isin(nearby_stores), nullable=True),\n",
    "        \"price\": Column(int, Check.less_than(5)),\n",
    "    }\n",
    ")\n",
    "schema.validate(fruits)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b77d8e6f-79fc-4a86-a857-31599fb2fc43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Deal with Duplicates - \\nschema = pa.DataFrameSchema(\\n    {\\n        \"name\": Column(str, Check.isin(available_fruits)),\\n        \"store\": Column(\\n            str, Check.isin(nearby_stores), nullable=True, allow_duplicates=False\\n        ),\\n        \"price\": Column(int, Check.less_than(5)),\\n    }\\n)\\nschema.validate(fruits)'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Deal with Duplicates - \n",
    "schema = pa.DataFrameSchema(\n",
    "    {\n",
    "        \"name\": Column(str, Check.isin(available_fruits)),\n",
    "        \"store\": Column(\n",
    "            str, Check.isin(nearby_stores), nullable=True, allow_duplicates=False\n",
    "        ),\n",
    "        \"price\": Column(int, Check.less_than(5)),\n",
    "    }\n",
    ")\n",
    "schema.validate(fruits)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6fb3bed0-bebd-4a83-aece-fe897251bd22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Convert Data Types - coerce=True changes the data type of a column\\nfruits = pd.DataFrame(\\n    {\\n        \"name\": [\"apple\", \"banana\", \"apple\", \"orange\"],\\n        \"store\": [\"Aldi\", \"Walmart\", \"Walmart\", \"Aldi\"],\\n        \"price\": [2, 1, 3, 4],\\n    }\\n)\\n\\nschema = pa.DataFrameSchema({\"price\": Column(str, coerce=True)})\\nvalidated = schema.validate(fruits)\\nvalidated.dtypes'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Convert Data Types - coerce=True changes the data type of a column\n",
    "fruits = pd.DataFrame(\n",
    "    {\n",
    "        \"name\": [\"apple\", \"banana\", \"apple\", \"orange\"],\n",
    "        \"store\": [\"Aldi\", \"Walmart\", \"Walmart\", \"Aldi\"],\n",
    "        \"price\": [2, 1, 3, 4],\n",
    "    }\n",
    ")\n",
    "\n",
    "schema = pa.DataFrameSchema({\"price\": Column(str, coerce=True)})\n",
    "validated = schema.validate(fruits)\n",
    "validated.dtypes'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "32f0aa48-6d18-4fde-9f29-2ed684521678",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Match Patterns - change all columns that start with the word \\'store\\', by adding regex=True\\n\\nfavorite_stores = [\"Aldi\", \"Walmart\", \"Whole Foods\", \"Schnucks\"]\\n\\nfruits = pd.DataFrame(\\n    {\\n        \"name\": [\"apple\", \"banana\", \"apple\", \"orange\"],\\n        \"store_nearby\": [\"Aldi\", \"Walmart\", \"Walmart\", \"Aldi\"],\\n        \"store_far\": [\"Whole Foods\", \"Schnucks\", \"Whole Foods\", \"Schnucks\"],\\n    }\\n)\\n\\nschema = pa.DataFrameSchema(\\n    {\\n        \"name\": Column(str, Check.isin(available_fruits)),\\n        \"store_+\": Column(str, Check.isin(favorite_stores), regex=True),\\n    }\\n)\\nschema.validate(fruits)'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Match Patterns - change all columns that start with the word 'store', by adding regex=True\n",
    "\n",
    "favorite_stores = [\"Aldi\", \"Walmart\", \"Whole Foods\", \"Schnucks\"]\n",
    "\n",
    "fruits = pd.DataFrame(\n",
    "    {\n",
    "        \"name\": [\"apple\", \"banana\", \"apple\", \"orange\"],\n",
    "        \"store_nearby\": [\"Aldi\", \"Walmart\", \"Walmart\", \"Aldi\"],\n",
    "        \"store_far\": [\"Whole Foods\", \"Schnucks\", \"Whole Foods\", \"Schnucks\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "schema = pa.DataFrameSchema(\n",
    "    {\n",
    "        \"name\": Column(str, Check.isin(available_fruits)),\n",
    "        \"store_+\": Column(str, Check.isin(favorite_stores), regex=True),\n",
    "    }\n",
    ")\n",
    "schema.validate(fruits)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3e761a23-f440-492a-9fad-168af34601ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from pathlib import Path\\n\\n# Get a YAML object\\nyaml_schema = schema.to_yaml()\\n\\n# Save to a file\\nf = Path(\"schema.yml\")\\nf.touch()\\nf.write_text(yaml_schema)'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export to YAML - neat way to show your tests\n",
    "\n",
    "'''from pathlib import Path\n",
    "\n",
    "# Get a YAML object\n",
    "yaml_schema = schema.to_yaml()\n",
    "\n",
    "# Save to a file\n",
    "f = Path(\"schema.yml\")\n",
    "f.touch()\n",
    "f.write_text(yaml_schema)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "29a72e74-652c-47ad-bfa8-de557b3b2b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'with f.open() as file:\\n    yaml_schema = file.read()\\n\\nschema = pa.io.from_yaml(yaml_schema)'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load from YAML\n",
    "\n",
    "'''with f.open() as file:\n",
    "    yaml_schema = file.read()\n",
    "\n",
    "schema = pa.io.from_yaml(yaml_schema)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8b6bf9-48a6-45c3-b838-0707f8d70280",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2eef81-fcbf-4d8c-bbf8-bfcb8958b43b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
